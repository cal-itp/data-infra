{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d0025de-fa9c-4c54-96bf-4a6b30f022f3",
   "metadata": {},
   "source": [
    "# RT metadata migration\n",
    "\n",
    "This notebook was used for migrating some old RT metadata. Generally our pattern is to identify all the files then iterate over them, manually mapping from old metadata in dictionary form and using the new metadata class (GTFSRTFeedExtract in this case) to set the new metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4dddb-a880-46d5-986e-3f92c812d254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do this first and restart kernel\n",
    "%pip install pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf8d01-fd85-4675-be80-7d5279a339b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calitp_data.storage import get_fs\n",
    "\n",
    "fs = get_fs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef620194-acea-4bca-b651-b51aa207f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "RT_BUCKET = \"test-calitp-gtfs-rt-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0aff7-0317-4d0a-914a-d70744850f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "from functools import lru_cache\n",
    "from typing import Dict\n",
    "\n",
    "import pendulum\n",
    "from calitp_data_infra.storage import (\n",
    "    AirtableGTFSDataExtract,\n",
    "    AirtableGTFSDataRecord,\n",
    "    get_latest_file,\n",
    ")\n",
    "\n",
    "# os.environ[\"CALITP_BUCKET__AIRTABLE\"] =\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def get_airtable_gtfs_records_for_day(\n",
    "    dt: pendulum.Date,\n",
    ") -> Dict[str, AirtableGTFSDataRecord]:\n",
    "    file = get_latest_file(\n",
    "        # AirtableGTFSDataExtract.bucket,\n",
    "        \"gs://test-calitp-airtable\",\n",
    "        AirtableGTFSDataExtract.table,\n",
    "        prefix_partitions={\n",
    "            \"dt\": dt,\n",
    "        },\n",
    "        partition_types={\n",
    "            \"ts\": pendulum.DateTime,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    with get_fs().open(file.name, \"rb\") as f:\n",
    "        content = gzip.decompress(f.read())\n",
    "    records = [\n",
    "        AirtableGTFSDataRecord(**json.loads(row))\n",
    "        for row in content.decode().splitlines()\n",
    "    ]\n",
    "\n",
    "    return {record.id: record for record in records}\n",
    "\n",
    "\n",
    "def schedule_record_ids_for_validation_to_actual_url(dt, record_ids):\n",
    "    if not record_ids:\n",
    "        return None\n",
    "    if len(record_ids) == 1:\n",
    "        records = get_airtable_gtfs_records_for_day(dt)\n",
    "        return records[record_ids[0]].uri\n",
    "    raise RuntimeError\n",
    "\n",
    "\n",
    "len(get_airtable_gtfs_records_for_day(pendulum.Date(2022, 8, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7b376-2ae5-4910-bb63-a6e2319c5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(project=\"cal-itp-data-infra\")\n",
    "blobs = list(tqdm(client.list_blobs(RT_BUCKET, prefix=f\"vehicle_positions/dt=2022-08-20/\", delimiter=None)))\n",
    "len(blobs), blobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fea254-497c-4e34-ba22-408d2c6e6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba930256-759f-45c6-b256-ac4fb2731ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of RT files to update\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_files_type_day(typ, dt, leave_pbar=True):\n",
    "    # proto_files = fs.expand_path(f'gs://{RT_BUCKET}/{typ}/dt={dt}', recursive=True)\n",
    "    files = client.list_blobs(RT_BUCKET, prefix=f\"{typ}/dt={dt}/\", delimiter=None)\n",
    "    return [\n",
    "        file\n",
    "        for file in tqdm(\n",
    "            files, desc=\"Filtering out directories\", leave=leave_pbar\n",
    "        )\n",
    "        if fs.stat(file)[\"type\"] != \"directory\"\n",
    "    ]\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "PARTITIONED_ARTIFACT_METADATA_KEY = \"PARTITIONED_ARTIFACT_METADATA\"\n",
    "\n",
    "\n",
    "def get_metadata(files, leave_pbar=True):\n",
    "    metadatas = []\n",
    "    missing_metadata = []\n",
    "    for file in tqdm(files, desc=\"Getting metadata\", leave=leave_pbar):\n",
    "        try:\n",
    "            metadatas.append(\n",
    "                (file, json.loads(fs.getxattr(file, PARTITIONED_ARTIFACT_METADATA_KEY)))\n",
    "            )\n",
    "        except KeyError:\n",
    "            missing_metadata.append(file)\n",
    "    return metadatas, missing_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db1fef-15f7-4181-863c-b57b7195fba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = handle_type_day(typ=\"vehicle_positions\", dt=\"2022-08-12\")\n",
    "metadatas, missing = get_metadata(files)\n",
    "len(files), len(metadatas), len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b06ff-351c-469b-97c6-c5394d3aef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_without_config = [meta for meta in metadatas if \"config\" not in meta[1]]\n",
    "files_without_config, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350b7a4-e0eb-4093-8fd7-3811b481b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sorted(metadatas, key=lambda m: m[1][\"ts\"], reverse=True)[0],\n",
    "    set(\n",
    "        json.dumps(metadata[\"config\"][\"auth_query_param\"])\n",
    "        for (file, metadata) in metadatas\n",
    "    ),\n",
    "    # set(json.dumps(metadata[\"config\"][\"auth_headers\"]) for (file, metadata) in metadatas),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151aea1-0cd7-4b53-bc42-7680964bca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pendulum\n",
    "from calitp_data_infra.storage import (\n",
    "    PARTITIONED_ARTIFACT_METADATA_KEY,\n",
    "    GTFSDownloadConfig,\n",
    "    GTFSRTFeedExtract,\n",
    ")\n",
    "\n",
    "\n",
    "def update_metadata(filepath, meta, write=False):\n",
    "    meta = meta.copy()\n",
    "    config = meta.pop(\"config\")\n",
    "    ts = pendulum.parse(meta.pop(\"ts\"), exact=True)\n",
    "    assert config\n",
    "    uri = config[\"uri\"]\n",
    "    if \"goswift.ly\" in uri:\n",
    "        headers = {\"authorization\": \"SWIFTLY_AUTHORIZATION_KEY_CALITP\"}\n",
    "    elif \"west-hollywood\" in uri:\n",
    "        headers = {\"x-umo-iq-api-key\": \"WEHO_RT_KEY\"}\n",
    "    else:\n",
    "        headers = {}\n",
    "    schedule_url = schedule_record_ids_for_validation_to_actual_url(\n",
    "        dt=ts.date(), record_ids=config[\"schedule_to_use_for_rt_validation\"]\n",
    "    )\n",
    "    extract = GTFSRTFeedExtract(\n",
    "        ts=ts,\n",
    "        config=GTFSDownloadConfig(\n",
    "            name=config.get(\"name\"),\n",
    "            url=uri,\n",
    "            feed_type=config[\"data\"],\n",
    "            schedule_url_for_validation=None,\n",
    "            auth_query_params=config[\"auth_query_param\"],\n",
    "            auth_headers=headers,\n",
    "        ),\n",
    "        **meta,\n",
    "    )\n",
    "    if write:\n",
    "        pass\n",
    "        # fs.setxattr(**{PARTITIONED_ARTIFACT_METADATA_KEY: extract.json()})\n",
    "\n",
    "\n",
    "for filepath, meta in tqdm(metadatas, desc=\"Updating metadatas\"):\n",
    "    update_metadata(filepath, meta, write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7ff1c-31a4-4885-9917-6da9ac1b9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_pbar = tqdm([\"service_alerts\", \"vehicle_positions\", \"trip_updates\"])\n",
    "for typ in typ_pbar:\n",
    "    typ_pbar.set_description(typ)\n",
    "    raw_dts_pbar = tqdm(\n",
    "        [fpath.split(\"/\")[-1] for fpath in fs.ls(f\"gs://{RT_BUCKET}/{typ}/\")],\n",
    "        leave=False,\n",
    "    )\n",
    "    for dt in raw_dts_pbar:\n",
    "        raw_dts_pbar.set_description(dt)\n",
    "        _, dt_str = dt.split(\"=\")\n",
    "        files = get_files_type_day(\n",
    "            typ=\"vehicle_positions\", dt=\"2022-08-12\", leave_pbar=False\n",
    "        )\n",
    "        metadatas, missing = get_metadata(files, leave_pbar=False)\n",
    "        for filepath, meta in tqdm(metadatas, desc=\"Updating metadatas\", leave=False):\n",
    "            update_metadata(filepath, meta, write=False)\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9358a-50fa-4969-a8c5-c71082d066f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
