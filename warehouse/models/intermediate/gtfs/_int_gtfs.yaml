version: 2

models:
  - name: int_gtfs_schedule__joined_feed_outcomes
    description: |
      Each row is an individual download attempt combined with the associated unzip and parse attempts for
      a given feed on a given date.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - base64_url
            - ts
    columns:
      - name: ts
      - name: base64_url
      - name: _config_extract_ts
      - name: download_success
      - name: download_exception
      - name: unzip_success
      - name: unzip_exception
      - name: zipfile_extract_md5hash
      - name: zipfile_files
      - name: zipfile_dirs
      - name: pct_files_successfully_parsed
  - name: int_gtfs_schedule__grouped_feed_file_parse_outcomes
    description: |
      Each row is a feed (URL + timestamp), with a summary of whether parsing was successful on the constituent files
      within that feed.
      "Success" means that the raw input file (usually a .txt file) was converted to JSONL format without an error.
      This does not guarantee validity according to the GTFS specification, just that the original input file was
      parseable on a pure file-format level (i.e., the file was not corrupt.)
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - base64_url
            - ts
    columns:
      - name: base64_url
      - name: ts
      - name: count_successes
        description: |
          Number of successful file conversions within this feed.
      - name: count_files
        description: |
          Number of total file conversions attempted for this feed.
      - name: pct_success
        description: '{{ doc("column_pct_sucesss") }}'

  - name: int_gtfs_schedule__long_calendar
    description: |
      This table transforms the raw GTFS calendar.txt format (where each row corresponds to a `service_id` and
      each day of the week is a column and service indicators are entered in a "wide" fashion)
      into a long format, where a row is identified by `feed_key`, `service_id`, and `date`.
      Rows are dropped if they have start_date > end_date (which is not valid) or if they have
      start_date more than a year in the future relative to the date the table is run.
    columns:
      - &schedule_key
        name: key
        description:
          Synthetic key from `service_id`, `feed_key`, and `service_date`.
        tests:
          - unique
          - not_null
      - &feed_key
        name: feed_key
        description: Foreign key for `dim_schedule_feeds`.
        tests:
          - not_null
          - relationships:
              to: ref('dim_schedule_feeds')
              field: key
      - name: _feed_valid_from
        tests:
          - not_null
      - name: service_id
        description: '{{ doc("gtfs_calendar__service_id") }}'
      - &service_date
        name: service_date
        description: |
          Date on which this service was active (i.e., this date is betweem the
          `start_date` and `end_date` for this service).
      - name: day_num
        description: |
          Day of week as number (Sunday = 1, Saturday = 7).
      - name: service_bool
        description: |
          Boolean indicating whether there is service for this `service_id` / `date` pair.
        tests:
          - not_null:
              # TODO: remove this once we deal with Auburn feed that has tab-delimited files
              where: "feed_key != '6368fe701bdd68c4f521751a9a222a10'"
      - name: calendar_key
        description: |
          Foreign key to dim_calendar.
        tests:
          - relationships:
              to: ref('dim_calendar')
              field: key
      - &feed_timezone_no_tests
        name: feed_timezone
        description: '{{ doc("gtfs_schedule_feed_timezone") }}'

  - name: int_gtfs_schedule__daily_scheduled_service_index
    description: |
      An index listing date, feed, and `service_id` combinations for which service was scheduled (i.e.,
      the `service_id` is "in effect" and says that service occurred).
      Essentially, it takes `calendar` and `calendar_dates` for a given feed, takes the dates for which that
      feed was "in effect", and combines those into a long list of all service_ids that were in effect for a given
      date, then filters down to only those where service was actually scheduled on that date.
      For example, a row in this table with `feed_key = A`, `service_date = 2022-10-01`, `service_id = 1` indicates
      that:
      * Feed A was online on 2022-10-01
      * Service ID 1 covers the date 2022-10-01, i.e., if service ID 1 is defined in `calendar.txt`,
         `start_date <= 2022-10-01 <= end_date` and if service ID ` is defined in `calendar_dates.txt`,
         `2022-10-01` is listed as a `date` within that file.
      * The service indicator is `true` for 2022-10-01 (a Saturday). So, if this service was defined in `calendar.txt`,
         `saturday = 1` for `service_id = 1`, and there is no `exception_type = 2` in `calendar_dates.txt` for this service and date.
         If this service is defined exclusively in `calendar_dates.txt`, then `exception_type = 1` is listed for `2022-10-01` in that file.
      This table therefore excludes `service_id` values which were in effect (i.e., feed was online and date range of service
      overlaps with service date) but where service was not scheduled.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - feed_key
            - service_date
            - service_id
    columns:
      - *feed_key
      - name: calendar_key
        description: |
          Foreign key for `dim_calendar`. If null, the service for this date was
          defined exclusively via `calendar_dates`.
        tests:
          - relationships:
              to: ref('dim_calendar')
              field: key
      - name: calendar_dates_key
        description: |
          Foreign key for `dim_calendar_dates`. If null, the service for this date was
          defined exclusively via `calendar`.
        tests:
          - relationships:
              to: ref('dim_calendar_dates')
              field: key
      - name: service_date
        description: Date on which service was scheduled.
        tests:
          - not_null
      - name: service_id
        description: Service identifier from calendar and/or calendar_dates.
        tests:
          - not_null
      - *feed_timezone_no_tests

  - name: int_gtfs_rt__unioned_parse_outcomes
    description: |
      A unioned combination of the parse outcomes for service alerts,
      vehicle positions, and trip updates data.
    columns:
      - name: dt
      - name: hour
        description: |
          Starting timestamp of hour in which data was downloaded, like `2022-10-31 23:00:00 UTC`.
      - name: name
      - name: url
      - name: feed_type,
      - name: _config_extract_ts,
      - name: schedule_url_for_validation,
      - name: parse_success
        description: |
          Boolean success indicator for whether this raw data was successfully included
          in the associated hourly aggregation.
      - name: parse_exception
        description: |
          If `parse_success` is false, the associated exception.
      - name: download_response_code
      - name: download_response_headers
      - name: step
      - name: base64_url
      - name: ts
      - name: last_modified_string
      - name: last_modified_timestamp
      - name: extract_ts

  - name: int_gtfs_schedule__keyed_parse_outcomes
    description: |
      All GTFS schedule file parse outcomes, with `feed_key` identifier joined
      on to facilitate downstream use.
    tests:
      - dbt_utils.equal_rowcount:
          compare_model: ref('stg_gtfs_schedule__file_parse_outcomes')
    columns:
      - name: feed_key
        description: |
          Foreign key to `dim_schedule_feeds`.
          Because `dim_schedule_feeds` only includes unique feed versions, this will not be populated
          for downloads where no data changed relative to what had already been ingested.
        tests:
          - relationships:
              to: ref('dim_schedule_feeds')
              field: key
      - name: parse_success
        description: '{{ doc("column_schedule_parse_success") }}'
      - name: parse_exception
        description: '{{ doc("column_schedule_parse_exception") }}'
      - name: filename
        description: '{{ doc("column_schedule_parse_filename") }}'
      - name: _config_extract_ts
      - name: feed_name
        description: '{{ doc("column_schedule_parse_feed_name") }}'
      - name: feed_url
        description: '{{ doc("column_schedule_parse_feed_url") }}'
      - name: original_filename
        description: '{{ doc("column_schedule_parse_original_filename") }}'
      - name: gtfs_filename
        description: '{{ doc("column_schedule_parse_gtfs_filename") }}'
      - name: dt
      - name: ts
      - name: base64_url
  - name: int_gtfs_schedule__stop_times_grouped
    description: |
      Stop times grouped by trip_id with trip aggregation calculations.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - feed_key
            - trip_id
            - iteration_num
      - dbt_utils.expression_is_true:
          expression: "num_regularly_scheduled_pickup_stop_times + num_no_pickup_stop_times + num_phone_call_required_for_pickup_stop_times + num_coordinate_pickup_with_driver_stop_times = num_stop_times"
      - dbt_utils.expression_is_true:
          expression: "num_regularly_scheduled_drop_off_stop_times + num_no_drop_off_stop_times + num_phone_call_required_for_drop_off_stop_times + num_coordinate_drop_off_with_driver_stop_times = num_stop_times"
      - dbt_utils.expression_is_true:
          expression: "num_continuous_pickup_stop_times + num_no_continuous_pickup_stop_times + num_phone_call_required_for_continuous_pickup_stop_times + num_coordinate_continuous_pickup_with_driver_stop_times = num_stop_times"
      - dbt_utils.expression_is_true:
          expression: "num_continuous_drop_off_stop_times + num_no_continuous_drop_off_stop_times + num_phone_call_required_for_continuous_drop_off_stop_times + num_coordinate_continuous_drop_off_with_driver_stop_times = num_stop_times"
      - dbt_utils.expression_is_true:
          expression: "num_approximate_timepoint_stop_times + num_exact_timepoint_stop_times = num_stop_times"
      - dbt_utils.expression_is_true:
          expression: "(num_gtfs_flex_stop_times > 0) = is_gtfs_flex_trip"
    columns:
      - *feed_key
      - name: trip_id
      - name: num_distinct_stops_served
        description: '{{ doc("column_num_distinct_stops_served") }}'
      - name: num_stop_times
        description: '{{ doc("column_num_stop_times") }}'
      - name: trip_first_departure_sec
      - name: trip_last_arrival_sec
      - name: service_hours
        description: '{{ doc("column_service_hours") }}'
      - name: flex_service_hours
        description: '{{ doc("column_flex_service_hours") }}'
      - name: contains_warning_duplicate_stop_times_primary_key
        description: '{{ doc("column_contains_warning_duplicate_stop_times_primary_key") }}'
      - name: contains_warning_missing_foreign_key_stop_id
        description: '{{ doc("column_contains_warning_missing_foreign_key_stop_id") }}'
      - name: frequencies_defined_trip
        description: '{{ doc("column_frequencies_defined_trip") }}'
      - name: exact_times
        description: |
          Only populated for frequencies-defined trips; see dim_frequencies.exact_times.
      - name: iteration_num
        description: '{{ doc("column_st_iteration_num") }}'
      - name: trip_start_timezone
        description: '{{ doc("column_trip_start_timezone") }}'
      - name: trip_end_timezone
        description: '{{ doc("column_trip_end_timezone") }}'
      - name: is_gtfs_flex_trip
        description: '{{ doc("column_is_gtfs_flex_trip") }}'
      - name: is_entirely_demand_responsive_trip
        description: '{{ doc("column_is_entirely_demand_responsive_trip") }}'
      - name: has_rider_service
        description: '{{ doc("column_has_rider_service") }}'
      - name: num_gtfs_flex_stop_times
        description: '{{ doc("column_num_gtfs_flex_stop_times") }}'
      - name: first_start_pickup_drop_off_window_sec
        description: '{{ doc("column_first_start_pickup_drop_off_window_sec") }}'
      - name: last_end_pickup_drop_off_window_sec
        description: '{{ doc("column_last_end_pickup_drop_off_window_sec") }}'
      - name: num_regularly_scheduled_pickup_stop_times
        description: '{{ doc("column_num_regularly_scheduled_pickup_stop_times") }}'
      - name: num_no_pickup_stop_times
        description: '{{ doc("column_num_no_pickup_stop_times") }}'
      - name: num_phone_call_required_for_pickup_stop_times
        description: '{{ doc("column_num_phone_call_required_for_pickup_stop_times") }}'
      - name: num_coordinate_pickup_with_driver_stop_times
        description: '{{ doc("column_num_coordinate_pickup_with_driver_stop_times") }}'
      - name: num_regularly_scheduled_drop_off_stop_times
        description: '{{ doc("column_num_regularly_scheduled_drop_off_stop_times") }}'
      - name: num_no_drop_off_stop_times
        description: '{{ doc("column_num_no_drop_off_stop_times") }}'
      - name: num_phone_call_required_for_drop_off_stop_times
        description: '{{ doc("column_num_phone_call_required_for_drop_off_stop_times") }}'
      - name: num_coordinate_drop_off_with_driver_stop_times
        description: '{{ doc("column_num_coordinate_drop_off_with_driver_stop_times") }}'
      - name: num_continuous_pickup_stop_times
        description: '{{ doc("column_num_continuous_pickup_stop_times") }}'
      - name: num_no_continuous_pickup_stop_times
        description: '{{ doc("column_num_no_continuous_pickup_stop_times") }}'
      - name: num_phone_call_required_for_continuous_pickup_stop_times
        description: '{{ doc("column_num_phone_call_required_for_continuous_pickup_stop_times") }}'
      - name: num_coordinate_continuous_pickup_with_driver_stop_times
        description: '{{ doc("column_num_coordinate_continuous_pickup_with_driver_stop_times") }}'
      - name: num_continuous_drop_off_stop_times
        description: '{{ doc("column_num_continuous_drop_off_stop_times") }}'
      - name: num_no_drop_off_stop_times
        description: '{{ doc("column_num_no_drop_off_stop_times") }}'
      - name: num_phone_call_required_for_continuous_drop_off_stop_times
        description: '{{ doc("column_num_phone_call_required_for_continuous_drop_off_stop_times") }}'
      - name: num_coordinate_continuous_drop_off_with_driver_stop_times
        description: '{{ doc("column_num_coordinate_continuous_drop_off_with_driver_stop_times") }}'
      - name: num_approximate_timepoint_stop_times
        description: '{{ doc("column_num_approximate_timepoint_stop_times") }}'
      - name: num_exact_timepoint_stop_times
        description: '{{ doc("column_num_exact_timepoint_stop_times") }}'
      - name: num_arrival_times_populated_stop_times
        description: '{{ doc("column_num_arrival_times_populated_stop_times") }}'
      - name: num_departure_times_populated_stop_times
        description: '{{ doc("column_num_departure_times_populated_stop_times") }}'
      - name: stop_pt_array
        description: |
          Array of ordered stop point geometries (dim_stop's pt_geom) for this trip_id.
      - name: stop_id_array
        description: |
          Array of ordered stop IDs (dim_stop's stop_id) for this trip_id.
      - name: stop_seq_array
        description: |
          Array of ordered stop sequences (dim_stop_time's stop_sequence) for this trip_id.
      - name: arrival_sec_array
        description: |
          Array of ordered arrival seconds (dim_stop_time's arrival_time, departure_time converted to seconds from midnight)
          for this trip_id. The minimum value between the two columns is used.
      - name: avg_stop_spacing
        description: |
          The average distance between stops for this trip_id.
          The difference between shape_dist_traveled is calculated for each ordered stop_id-stop_sequence,
          and the average is taken across the stops included for the trip.
          Units are the same as values provided in https://gtfs.org/documentation/schedule/reference/#stop_timestxt.
          Note: this is an optional column in the GTFS specification, so may not be present for all operators.
  - name: int_gtfs_rt__distinct_download_configs
    description: |
      Distinct `dt`, `_config_extract_ts` pairs indicating
      the configuration versions that were in effect for a given date of RT data.
      This allows us to reconstruct what URLs were in our configuration list for each date.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - dt
            - _config_extract_ts
    columns:
      - name: dt
        description: Date that RT data was extracted.
      - name: _config_extract_ts
        description: Timestamp that download config file was extracted.
  - name: int_gtfs_rt__daily_url_index
    description: |
      All RT URLs that were present at least once for each given day.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - dt
            - base64_url
    columns:
      - name: dt
        description: |
          Date that this URL was present in an active download configuration,
          indicating that downloads should have been attempted for this URL
          on this date.
        tests:
          - not_null
      - name: string_url
        description: |
          URL in human-readable format.
        tests:
          - not_null
      - name: base64_url
        description: |
          Base64 encoded URL, can be used to join with other tables
          containing data from this feed.
        tests:
          - not_null
      - name: type
        description: |
          RT data type: "GTFS Alerts", "GTFS VehiclePositions", "GTFS TripUpdates".
        tests:
          - not_null
      - name: data_quality_pipeline
  - name: int_gtfs_schedule__all_scheduled_service
    description: |
      **Use with caution: This table lists service for all feeds, regardless of whether the given feed
      was actually "active" on the given day. To see only service for active feeds,
      consult `int_gtfs_schedule__daily_scheduled_service_index`.**
      Lists date, feed, and `service_id` combinations for which service was scheduled (i.e.,
      the `service_id` is "in effect" and says that service occurred).
      Essentially, it takes `calendar` and `calendar_dates` for a given feed and combines those into a long list of all service_ids that were in effect for a given
      date, then filters down to only those where service was actually scheduled on that date.
      For example, a row in this table with `feed_key = A`, `service_date = 2022-10-01`, `service_id = 1` indicates
      that:
      * Service ID 1 covers the date 2022-10-01, i.e., if service ID 1 is defined in `calendar.txt`,
         `start_date <= 2022-10-01 <= end_date` and if service ID 1 is defined in `calendar_dates.txt`,
         `2022-10-01` is listed as a `date` within that file.
      * The service indicator is `true` for 2022-10-01 (a Saturday). So, if this service was defined in `calendar.txt`,
         `saturday = 1` for `service_id = 1`, and there is no `exception_type = 2` in `calendar_dates.txt` for this service and date.
         If this service is defined exclusively in `calendar_dates.txt`, then `exception_type = 1` is listed for `2022-10-01` in that file.
    columns:
      - *schedule_key
      - *feed_key
      - name: _feed_valid_from
        tests:
          - not_null
      - name: calendar_key
        description: |
          Foreign key for `dim_calendar`. If null, the service for this date was
          defined exclusively via `calendar_dates`.
        tests:
          - relationships:
              to: ref('dim_calendar')
              field: key
      - name: calendar_dates_key
        description: |
          Foreign key for `dim_calendar_dates`. If null, the service for this date was
          defined exclusively via `calendar`.
        tests:
          - relationships:
              to: ref('dim_calendar_dates')
              field: key
      - name: service_date
        description: Date on which service was scheduled.
        tests:
          - not_null
      - name: service_id
        description: Service identifier from calendar and/or calendar_dates.
        tests:
          - not_null
      - *feed_timezone_no_tests
  - name: int_gtfs_schedule__frequencies_stop_times
    description: |
      Expands out frequency-based trips' stop times by combining dim_frequencies and dim_stop_times
      to list each scheduled iteration of a trip.
      See https://gtfs.org/schedule/reference/#frequenciestxt for interpretation of frequency-based trips.
    columns:
      - *feed_key
      - name: trip_id
      - name: stop_id
      - name: iteration_num
        description: |
          For a frequency-based trip, there will be ((`end_time_sec` - 1) - `start_time_sec`) / `headway_secs`
          iterations of a given trip. This field gives a zero-based index for what instance number this is.
          So, `trip_start_time_sec = frequency_start_time_sec + iteration_num * headway_secs`.
      - name: trip_start_time_sec
        description: |
          This is a calculated field that does not come directly from GTFS - it is not a timestamp and can't be treated as such.

          Represents this trip iteration's `start_time` as a total number of seconds after twelve hours before noon (usually midnight) of the first day of the given trip.
          For example, `frequencies.start_time = 21:30:45` with `frequencies.headway_secs = 600` (ten minute headways)
          would lead to `frequency_start_time_sec = 21 * 3,600 + 30 * 60 + 45 * 1 = 77,445`.
          There will then be `trip_start_time_sec` of `77,445` (the same as the frequency start time),
          `78,045 = 77,445 + 600`, and so on, adding `headway_secs` again and again until we reach `frequency_end_time_sec - 1`.

          Using a count of seconds allows us to perform duration calculations and handle timestamps that wrap past midnight like
          `25:40:00`, which are allowed in GTFS. See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: trip_stop_arrival_time_sec
        description: |
          This is a calculated field that does not come directly from GTFS - it is not a timestamp and can't be treated as such.

          Represents this trip iteration's `arrival_time` at the given stop as a total number of seconds after twelve hours before noon (usually midnight) of the first day of the given trip.
          Say `trip_start_time_sec` = `78,045`. We then calculate the individual stop's arrival time for this iteration based on the duration between it and the first stop
          in `stop_times`.

          So if the `stop_times.departure_time` for the trip's first stop was `00:00:00 = 0 seconds` and
          the `stop_times.arrival_time` at a given stop was `00:05:00 = 300 seconds` then the `trip_stop_arrival_time_sec`
          would be `78,045 + 300 = 81,045`.

          Using a count of seconds allows us to perform duration calculations and handle timestamps that wrap past midnight like
          `25:40:00`, which are allowed in GTFS. See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: trip_stop_departure_time_sec
        description: |
          This is a calculated field that does not come directly from GTFS - it is not a timestamp and can't be treated as such.

          Represents this trip iteration's `departure_time` at the given stop as a total number of seconds after twelve hours before noon (usually midnight) of the first day of the given trip.
          Say `trip_start_time_sec` = `78,045`. We then calculate the individual stop's departure time for this iteration based on the duration between it and the first stop
          in `stop_times`.

          So if the `stop_times.departure_time` for the trip's first stop was `00:00:00 = 0 seconds` and
          the `stop_times.departure_time` at a given stop was `00:05:00 = 300 seconds` then the `trip_stop_departure_time_sec`
          would be `78,045 + 300 = 81,045`.

          Using a count of seconds allows us to perform duration calculations and handle timestamps that wrap past midnight like
          `25:40:00`, which are allowed in GTFS. See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: trip_start_time_interval
        description: |
          This is a calculated field that does not appear directly in GTFS. It contains the same data as `trip_start_time_sec`
          as a BigQuery INTERVAL type, which allows us to treat the field as a duration after twelve hours before noon (usually midnight)
          and thus handle times past the following midnight (like `25:40:00`).
          See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: trip_stop_arrival_time_interval
        description: |
          This is a calculated field that does not appear directly in GTFS. It contains the same data as `trip_stop_arrival_time_sec`
          as a BigQuery INTERVAL type, which allows us to treat the field as a duration after twelve hours before noon (usually midnight)
          and thus handle times past the following midnight (like `25:40:00`).
          See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: stop_sequence
        description: |
          '{{ doc("gtfs_stop_times__stop_sequence") }}'
      - name: frequency_start_time
        description: |
          '{{ doc("gtfs_frequencies__start_time") }}'
      - name: frequency_end_time
        description: |
          '{{ doc("gtfs_frequencies__end_time") }}'
      - name: frequency_start_time_interval
        description: |
          This is a calculated field that does not appear directly in GTFS. It contains the same data as `frequency_start_time`
          as a BigQuery INTERVAL type, which allows us to treat the field as a duration after twelve hours before noon (usually midnight)
          and thus handle times past the following midnight (like `25:40:00`).
          See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: frequency_end_time_interval
        description: |
          This is a calculated field that does not appear directly in GTFS. It contains the same data as `frequency_end_time`
          as a BigQuery INTERVAL type, which allows us to treat the field as a duration after twelve hours before noon (usually midnight)
          and thus handle times past the following midnight (like `25:40:00`).
          See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: frequency_start_time_sec
        description: |
          This is a calculated field that does not come directly from GTFS - it is not a timestamp and can't be treated as such.

          Represents this `frequency_start_time` as a total number of seconds after twelve hours before noon (usually midnight) of the first day of the given trip.
          For example, `frequencies.start_time = 21:30:45` would lead to `frequency_start_time_sec = 21 * 3,600 + 30 * 60 + 45 * 1 = 77,445`.

          Using a count of seconds allows us to perform duration calculations and handle timestamps that wrap past midnight like
          `25:40:00`, which are allowed in GTFS. See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: frequency_end_time_sec
        description: |
          This is a calculated field that does not come directly from GTFS - it is not a timestamp and can't be treated as such.

          Represents this `frequency_end_time` as a total number of seconds after twelve hours before noon (usually midnight) of the first day of the given trip.
          For example, `frequencies.end_time = 21:30:45` would lead to `frequency_end_time_sec = 21 * 3,600 + 30 * 60 + 45 * 1 = 77,445`.

          Using a count of seconds allows us to perform duration calculations and handle timestamps that wrap past midnight like
          `25:40:00`, which are allowed in GTFS. See: https://gtfs.org/schedule/reference/#field-types for how GTFS defines its "Time" type.
      - name: headway_secs
        description: '{{ doc("gtfs_frequencies__headway_secs") }}'
      - name: exact_times
        description: '{{ doc("gtfs_frequencies__exact_times") }}'
      - name: first_trip_departure_sec
        description: |
          The `stop_times_departure_sec` of the first stop (lowest `stop_sequence` value) on this trip.
      - name: stop_times_arrival_sec
        description: |
          See `dim_stop_times.arrival_sec`.
      - name: stop_times_departure_sec
        description: |
          See `dim_stop_times.departure_sec`.
      - name: stop_times_arrival_time_interval
        description: |
          See `dim_stop_times.arrival_time_interval`.
      - name: stop_times_departure_time_interval
        description: |
          See `dim_stop_times.departure_time_interval`.
      - name: stop_times_arrival_time
        description: '{{ doc("gtfs_stop_times__arrival_time") }}'
      - name: stop_times_departure_time
        description: '{{ doc("gtfs_stop_times__departure_time") }}'
      - name: sec_to_stop
        description: |
          Number of seconds it takes on a given trip instance to get from the first stop to the current stop
          (calculated from `stop_times_arrival_sec - first_trip_departure_sec`).
      - name: stop_headsign
        description: '{{ doc("gtfs_stop_times__stop_headsign") }}'
      - name: pickup_type
        description: '{{ doc("gtfs_stop_times__pickup_type") }}'
      - name: drop_off_type
        description: '{{ doc("gtfs_stop_times__drop_off_type") }}'
      - name: shape_dist_traveled
        description: '{{ doc("gtfs_stop_times__shape_dist_traveled") }}'
      - name: timepoint
        description: '{{ doc("gtfs_stop_times__timepoint") }}'
      - name: warning_duplicate_gtfs_key
        description: |
          Rows with `true` in this column have a duplicate primary key; i.e., the given `trip_id`
          / `stop_sequence` pair is duplicated within an individual feed instance and `key` will
          also be duplicated as a result. Treat these rows with caution. They will cause fanout in joins.
      - name: warning_missing_foreign_key_stop_id
        description: |
          Rows with `true` in this column are missing the required `stop_id` value.
          This means they will fail to join with `stop` related information.
      - name: base64_url
      - name: _feed_valid_from
  - name: int_gtfs_rt__service_alerts_fully_unnested
    description: |
      This table contains GTFS RT service alerts messages with all elements (informed entities,
      active periods, and translations) unnested, so each row is a message / entity / active period /
      translation combination.
      See: https://gtfs.org/realtime/reference/#message-alert for field definitions.
    columns:
      - name: english_likelihood
        description: |
          100 if English language, 1 if null (null can mean no internationalization),
          0 for other languages. Based on `header_text.language`.
  - name: int_gtfs_rt__service_alerts_day_map_grouping
    description: |
      This table groups service alerts messages by `dt` (UTC) and `active_date` (usually Pacific)
      to enable:
        1. Incremental materialization based on `dt` (to make efficient use of upstream partitions)
        2. Downstream grouping by `active_date` alone (since that is the appropriate final grain for general "daily" work on service alerts)
      See downstream `fct_daily_service_alerts` table for further documentation.
  - name: int_gtfs_rt__service_alerts_trip_day_map_grouping
    description: |
      This table groups service alerts messages by `dt` (UTC) and `service_date` (usually Pacific)
      to enable:
        1. Incremental materialization based on `dt` (to make efficient use of upstream partitions)
        2. Downstream grouping by `service_date` alone (since that is the appropriate final grain for trip-based analysis)
      See downstream `fct_service_alerts_trip_summaries` table for further documentation.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - key
            - dt
            - service_date
            - trip_schedule_relationship
            - schedule_base64_url
          where: '__rt_sampled__'
  - name: int_gtfs_rt__trip_updates_trip_day_map_grouping
    description: |
      This table groups trip updates messages by `dt` (UTC) and `service_date` (usually Pacific)
      to enable:
        1. Incremental materialization based on `dt` (to make efficient use of upstream partitions)
        2. Downstream grouping by `service_date` alone (since that is the appropriate final grain for trip-based analysis)
      See downstream `fct_trip_updates_trip_summaries` table for further documentation.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - key
            - dt
            - service_date
            - trip_schedule_relationship
            - trip_route_id
            - trip_direction_id
            - schedule_base64_url
          # this will fail if run on all historical data, specifically for days where a given feed's time zone changed;
          # even then the number of failures is very small
          where: '__rt_sampled__'
  - name: int_gtfs_rt__vehicle_positions_trip_day_map_grouping
    description: |
      This table groups vehicle positions messages by `dt` (UTC) and `service_date` (usually Pacific)
      to enable:
        1. Incremental materialization based on `dt` (to make efficient use of upstream partitions)
        2. Downstream grouping by `service_date` alone (since that is the appropriate final grain for trip-based analysis)
      See downstream `fct_vehicle_positions_summaries` table for further documentation.
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - key
            - dt
            - service_date
            - trip_schedule_relationship
            - trip_route_id
            - trip_direction_id
            - schedule_base64_url
          # this will fail if run on all historical data, specifically for days where a given feed's time zone changed;
          # even then the number of failures is very small
          where: '__rt_sampled__'
  - name: int_gtfs_rt_vs_sched__stops_served_vehicle_positions
    description: |
      This table joins int_gtfs_schedule__stop_times_grouped (stop times grouped by trip)
      and fct_vehicle_locations_path (vehicle positions grouped by trip).
      It unnests the stop positions so that the table is unique on the
      feed_key-trip_instance_key-stop_id.

      The table buffers the scheduled stop's pt geom by 100 meters and
      checks whether the vehicle locations path (linestring) intersects
      with the buffered stop, to determine whether the stop is
      serviced by vehicle positions data.

    columns:
      - *feed_key
      - name: gtfs_dataset_key
      - *service_date
      - name: trip_id
        description: '{{ doc("gtfs_trips__trip_id") }}'
      - name: iteration_num
      - name: trip_instance_key
      - name: stop_id
        description: '{{ doc("gtfs_stops__stop_id") }}'
      - name: vp_near_stop
        description: |
          Boolean indicating whether the vehicle positions path got
          within the stop's 100 meter buffer.
