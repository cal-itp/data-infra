calitp_warehouse:
  target: staging
  outputs:
    prod:
      &prod
      execution_project: cal-itp-data-infra
      database: cal-itp-data-infra
      schema: staging
      fixed_retries: 1
      location: us-west2
      method: oauth
      priority: interactive
      threads: 8
      # currently slowest models are int_gtfs_rt__vehicle_positions_trip_day_map_grouping / int_gtfs_rt__trip_updates_trip_day_map_grouping
      # 3000 is not enough
      timeout_seconds: 5400
      type: bigquery
      gcs_bucket: calitp-dbt-python-models
      dataproc_region: us-west2
      submission_method: serverless
      dataproc_batch:
        runtime_config:
          container_image: gcr.io/cal-itp-data-infra/dbt-spark:2023.3.28
          properties:
            spark.executor.cores: "4" # this is the default but put it here for clarity
            spark.executor.instances: "4" # dbt defaults to 2
            spark.executor.memory: 4g
            spark.dynamicAllocation.maxExecutors: "16"
    prod_service_account:
      <<: *prod
      method: service-account
      keyfile: "{{ env_var('BIGQUERY_KEYFILE_LOCATION', '/secrets/jobs-data/service-account.json') }}"
    staging:
      &staging
      <<: *prod
      execution_project: cal-itp-data-infra-staging
      database: cal-itp-data-infra-staging
      schema: staging
      gcs_bucket: test-calitp-dbt-python-models
    staging_service_account:
      <<: *staging
      method: service-account
      keyfile: "{{ env_var('BIGQUERY_KEYFILE_LOCATION', '/secrets/jobs-data/service-account.json') }}"
