operator: 'operators.PodOperator'
name: 'deploy-dbt-docs-site'
image: 'ghcr.io/cal-itp/data-infra/warehouse:{{ image_tag() }}'

cmds:
  - python3
arguments:
  - '/app/scripts/run_and_upload.py'
  - 'run'
  - '--no-dbt-seed'
  - '--no-dbt-run'
  - '--dbt-docs'
  - '--save-artifacts'
  - '--deploy-docs'

is_delete_operator_pod: true
get_logs: true
is_gke: true
pod_location: us-west1
cluster_name: data-infra-apps
namespace: airflow-jobs
priority_class_name: dbt-high-priority

env_vars:
  AIRFLOW_ENV: "{{ env_var('AIRFLOW_ENV') }}"
  BIGQUERY_KEYFILE_LOCATION: /secrets/jobs-data/service_account.json
  CALITP_BUCKET__DBT_ARTIFACTS: "{{ env_var('CALITP_BUCKET__DBT_ARTIFACTS') }}"
  CALITP_BUCKET__DBT_DOCS: "{{ env_var('CALITP_BUCKET__DBT_DOCS') }}"
  DBT_PROJECT_DIR: /app
  DBT_PROFILE_DIR: /app
  DBT_TARGET: "{{ env_var('DBT_TARGET') }}"

secrets:
  - deploy_type: volume
    deploy_target: /secrets/jobs-data/
    secret: jobs-data
    key: service-account.json

tolerations:
  - key: pod-role
    operator: Equal
    value: computetask
    effect: NoSchedule

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: pod-role
          operator: In
          values:
          - computetask
